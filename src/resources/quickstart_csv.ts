export const QUICKSTART_CSV_GUIDE = `
# Guide: CSV Upload, Analysis, and Querying with Infactory

This is a step-by-step guide to using the available tools to upload a CSV file, analyze its contents, and generate insights.

## Step 1: Get Your Team ID

First, you need to know which team to create your project in. This is required for project creation.

**Tool Call:** \`get_current_user\`
**Example:** \`get_current_user\`
**Output:** Look for the \`teamId\` in the \`userTeams\` array from the response.

## Step 2: Create a Project

Create a new project to house your data and queries. Use a descriptive name.

**Tool Call:** \`create_project\`
**Parameters:**
- \`name\`: "My CSV Analysis Project"
- \`teamId\`: (Use the \`teamId\` from Step 1)
**Example:** \`create_project {\"name\": \"My CSV Analysis Project\", \"teamId\": \"team-...\"}\`
**Output:** Note the \`id\` of the newly created project. This is your \`projectId\`.

## Step 3: Upload Your CSV Data

Upload your local CSV file. This will create a "datasource" in your project.

**Tool Call:** \`upload_csv\`
**Parameters:**
- \`projectId\`: (Use the \`projectId\` from Step 2)
- \`filePath\`: "path/to/your/local/file.csv"
- \`datasourceName\`: "My Stock Data"
**Example:** \`upload_csv {\"projectId\": \"proj-...\", \"filePath\": \"/Users/claude/data/stocks.csv\", \"datasourceName\": \"Stock Prices CSV\"}\`
**Output:** Note the \`id\` of the new datasource. This is your \`datasourceId\`.

## Step 4: Wait for Data Processing

The platform needs a moment to process your CSV and infer its schema. Poll the datasource status until it becomes "ready".

**Tool Call:** \`get_datasource_status\`
**Parameters:**
- \`datasourceId\`: (Use the \`datasourceId\` from Step 3)
**Example:** \`get_datasource_status {\"datasourceId\": \"ds-...\"}\`
**Action:** Repeat this call every 5-10 seconds until the \`status\` field in the response is \`"ready"\`.

## Step 5: Discover Insights with Autogenerated Queries

Now that the data is ready, let the platform suggest some interesting questions to ask.

**Tool Call:** \`autogenerate_queries\`
**Parameters:**
- \`projectId\`: (Use the \`projectId\` from Step 2)
- \`count\`: 3 (optional, request a few questions)
**Example:** \`autogenerate_queries {\"projectId\": \"proj-...\"}\`
**Action:** Review the suggested queries. Pick one to run in the next step. Note its \`id\`.

## Step 6: Run an Autogenerated Query

Execute one of the queries generated in the previous step to see a sample analysis.

**Tool Call:** \`run_query_program\`
**Parameters:**
- \`projectId\`: (Use the \`projectId\` from Step 2)
- \`queryProgramId\`: (Use the \`id\` of a query from Step 5)
**Example:** \`run_query_program {\"projectId\": \"proj-...\", \"queryProgramId\": \"qp-...\"}\`
**Output:** Analyze the results to understand your data.

## Step 7: Ask Your Own Question

Create a custom query program by asking a question in natural language.

**Tool Call:** \`create_query_from_nl\`
**Parameters:**
- \`projectId\`: (Use the \`projectId\` from Step 2)
- \`question\`: "What was the highest price for each stock symbol?"
**Example:** \`create_query_from_nl {\"projectId\": \"proj-...\", \"question\": \"What is the average trading volume per symbol?\"}\`
**Output:** This will create a new query program. Note its \`id\` for the next step.

## Step 8: Run Your Custom Query

Execute the custom query you just created.

**Tool Call:** \`run_query_program\`
**Parameters:**
- \`projectId\`: (Use the \`projectId\` from Step 2)
- \`queryProgramId\`: (Use the \`id\` of the query from Step 7)
**Example:** \`run_query_program {\"projectId\": \"proj-...\", \"queryProgramId\": \"qp-...\"}\`

## Step 9: Cleanup (Optional)

Once you are finished, you can remove the resources you created.

**Tool Call:** \`delete_datasource\`
**Example:** \`delete_datasource {\"datasourceId\": \"ds-...\"}\`

**Tool Call:** \`delete_project\`
**Example:** \`delete_project {\"projectId\": \"proj-...\"}\`
`.trim();